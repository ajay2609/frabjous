{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports and configuration\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "\n",
    "# Logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s: %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Directories (overridable via environment)\n",
    "DATA_DIR = Path(os.environ.get(\"DATA_DIR\", \".\"))  # default: current directory\n",
    "MODELS_DIR = Path(os.environ.get(\"MODELS_DIR\", \"retrain_models\"))  # default: retrain_models in current directory\n",
    "OUT_DIR = Path(os.environ.get(\"OUT_DIR\", \".\"))  # default: current directory\n",
    "\n",
    "logger.info(\"Imports loaded. DATA_DIR=%s MODELS_DIR=%s OUT_DIR=%s\", DATA_DIR, MODELS_DIR, OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_model(name):\n",
    "    path = MODELS_DIR / name\n",
    "    try:\n",
    "        m = keras.models.load_model(str(path))\n",
    "        logger.info(\"Loaded model: %s\", name)\n",
    "        return m\n",
    "    except Exception as exc:\n",
    "        logger.warning(\"Could not load model %s: %s\", name, exc)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the models from the best models from the hyperparameter tuning of the all the binary cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal robust model loading (keeps original variable names)\n",
    "\n",
    "model_A_B = _load_model(\"model_A_B\")\n",
    "model_A_C = _load_model(\"model_A_C\")\n",
    "model_A_C1 = _load_model(\"model_A_C1\")\n",
    "model_A_C2 = _load_model(\"model_A_C2\")\n",
    "model_B_C = _load_model(\"model_B_C\")\n",
    "model_B_C1 = _load_model(\"model_B_C1\")\n",
    "model_B_C2 = _load_model(\"model_B_C2\")\n",
    "model_C_C1 = _load_model(\"model_C_C1\")\n",
    "model_C_C2 = _load_model(\"model_C_C2\")\n",
    "model_C1_C2 = _load_model(\"model_C1_C2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load input arrays (platform-independent)\n",
    "interp_path = DATA_DIR / \"chime_interp_frbs.npz\"\n",
    "model_path = DATA_DIR / \"chime_model_frbs.npz\"\n",
    "\n",
    "if not interp_path.exists() or not model_path.exists():\n",
    "    logger.error(\"Required data files missing: %s %s\", interp_path.as_posix(), model_path.as_posix())\n",
    "else:\n",
    "    with np.load(interp_path) as arr:\n",
    "        frb_data = arr[\"arr_0\"].astype(np.float32)\n",
    "    with np.load(model_path) as arr:\n",
    "        frb_model_data = arr[\"arr_0\"].astype(np.float32)\n",
    "    logger.info(\"Loaded data shapes: frb_data=%s frb_model_data=%s\", frb_data.shape, frb_model_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Plot one the images for sanity check  ########\n",
    "test_image = frb_data[0].copy()\n",
    "test_image = test_image/(test_image.max()/255)\n",
    "plt.imshow(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_to_test_data(interp_path):\n",
    "    \"\"\"\n",
    "    Read and normalize interpolated FRB test images from DATA_DIR.\n",
    "    Returns numpy array with shape (N, H, W, 1), dtype float32, values scaled 0-255.\n",
    "    \"\"\"\n",
    "\n",
    "    with np.load(interp_path) as frbdata:\n",
    "        frbd1 = frbdata[\"arr_0\"]\n",
    "\n",
    "    frbdn = []\n",
    "    for img in frbd1:\n",
    "        immax = img.max() \n",
    "        frbdn.append(img / (immax / 255.0))\n",
    "\n",
    "    frbdn = np.asarray(frbdn)      \n",
    "    frbdn.shape += 1,        \n",
    "    logger.info(\"Loaded %d images, shape=%s\", frbdn.shape[0], frbdn.shape)\n",
    "    return frbdn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = read_to_test_data(str(DATA_DIR / \"chime_interp_frbs.npz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions for the all the chime bursts with 10 binary models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_A_B   = model_A_B(test_images)\n",
    "pred_A_C   = model_A_C(test_images)\n",
    "pred_A_C1  = model_A_C1(test_images)\n",
    "pred_A_C2  = model_A_C2(test_images)\n",
    "pred_B_C   = model_B_C(test_images)\n",
    "pred_B_C1  = model_B_C1(test_images)\n",
    "pred_B_C2  = model_B_C2(test_images)\n",
    "pred_C_C1  = model_C_C1(test_images)\n",
    "pred_C_C2  = model_C_C2(test_images)\n",
    "pred_C1_C2 = model_C1_C2(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"pred_A_B\",\"pred_A_C\",\"pred_A_C1\",\"pred_A_C2\",\n",
    "         \"pred_B_C\",\"pred_B_C1\",\"pred_B_C2\",\n",
    "         \"pred_C_C1\",\"pred_C_C2\",\"pred_C1_C2\"]\n",
    "pred = [globals().get(n) for n in names if globals().get(n) is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix_from_pred(predictions, n):\n",
    "    \"\"\"\n",
    "    Convert the 10 binary-model predictions for sample index `n` into a numeric 5x5 matrix.\n",
    "\n",
    "    Expected `predictions` order (length 10):\n",
    "      [A_vs_B, A_vs_C, A_vs_C1, A_vs_C2,\n",
    "       B_vs_C, B_vs_C1, B_vs_C2,\n",
    "       C_vs_C1, C_vs_C2,\n",
    "       C1_vs_C2]\n",
    "\n",
    "    Returns:\n",
    "      np.ndarray shape (5,5) dtype float with np.nan on the diagonal.\n",
    "      Upper-triangle entries contain the model score for (row_class vs col_class)\n",
    "      and the symmetric lower-triangle is (1 - score).\n",
    "    \"\"\"\n",
    "\n",
    "    def _get_score(pred_array, idx):\n",
    "        arr = np.asarray(pred_array)\n",
    "        if arr.ndim == 1:\n",
    "            val = arr[idx]\n",
    "        else:\n",
    "            val = arr[idx].ravel()[0]\n",
    "        return float(val)\n",
    "\n",
    "    # mapping of prediction index -> (row, col) in 5x5 matrix (row < col)\n",
    "    map_indices = [\n",
    "        (0, 1), (0, 2), (0, 3), (0, 4),  # A vs B,C,C1,C2  -> preds[0..3]\n",
    "        (1, 2), (1, 3), (1, 4),          # B vs C,C1,C2     -> preds[4..6]\n",
    "        (2, 3), (2, 4),                  # C vs C1,C2       -> preds[7..8]\n",
    "        (3, 4)                           # C1 vs C2         -> preds[9]\n",
    "    ]\n",
    "\n",
    "    mat = np.zeros((5,5) , dtype=np.float32)\n",
    "    mat[mat==0]=2 \n",
    "\n",
    "    for pred_idx, (r, c) in enumerate(map_indices):\n",
    "        score = _get_score(predictions[pred_idx], n)\n",
    "        score = float(score)\n",
    "        mat[r, c] = round(score, 4)\n",
    "        mat[c, r] = round(1.0 - score, 4)\n",
    "    mat[mat==2]= np.nan    \n",
    "\n",
    "    return mat.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.zeros((5,5))\n",
    "thresholds[0][1] = 0.64    # A vs B \n",
    "thresholds[0][2] = 0.5    # A vs C \n",
    "thresholds[0][3] = 0.5    # A vs C1\n",
    "thresholds[0][4] = 0.5    # A vs C2 \n",
    "thresholds[1][0] = 0.36    # B vs A\n",
    "thresholds[1][2] = 0.5    # B vs C\n",
    "thresholds[1][3] = 0.2    # B vs C1\n",
    "thresholds[1][4] = 0.5    # B vs C2\n",
    "thresholds[2][0] = 0.5    # C vs A\n",
    "thresholds[2][1] = 0.5    # C vs B\n",
    "thresholds[2][3] = 0.5    # C vs C1\n",
    "thresholds[2][4] = 0.5    # C s C2\n",
    "thresholds[3][0] = 0.5    # C1 vs A\n",
    "thresholds[3][1] = 0.8    # C1 vs B\n",
    "thresholds[3][2] = 0.5    # C1 vs C\n",
    "thresholds[3][4] = 0.5    # C1 vs C2\n",
    "thresholds[4][0] = 0.5    # C2 vs A\n",
    "thresholds[4][1] = 0.5    # C2 vs B\n",
    "thresholds[4][2] = 0.5    # C2 vs C\n",
    "thresholds[4][3] = 0.5    # C2 s C1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_index = []\n",
    "confidences = []\n",
    "n_samples = len(frb_data)\n",
    "\n",
    "for num in range(n_samples):\n",
    "    test_matrix = conf_matrix_from_pred(pred, num)\n",
    "    test_matrix = np.asarray(test_matrix, dtype=np.float32) - thresholds.astype(np.float32)\n",
    "    mean_rows = np.nansum(test_matrix, axis=1)\n",
    "\n",
    "    if np.all(np.isnan(mean_rows)):\n",
    "        max_index.append(np.nan)\n",
    "    else:\n",
    "        max_index.append(int(np.nanargmax(mean_rows)))\n",
    "\n",
    "    confidences.append(mean_rows.astype(np.float32))\n",
    "\n",
    "confidences = np.vstack(confidences) if len(confidences) else np.empty((0, 5), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidences = np.array(confidences)\n",
    "print(confidences)\n",
    "## save he mean confidence scores which corresponds to the sum of each row\n",
    "np.save('/path/to/directory/all_scores.npy', confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = Path(\"All_scores.txt\")\n",
    "\n",
    "mapping = {0: \"I\", 1: \"II\", 2: \"III\", 3: \"IV\", 4: \"V\"}\n",
    "\n",
    "with out_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for val in max_index:\n",
    "        if val is None or (isinstance(val, float) and np.isnan(val)):\n",
    "            f.write(\"Unknown\\n\")\n",
    "            continue\n",
    "        f.write(f\"{mapping.get(int(val), 'Unknown')}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
