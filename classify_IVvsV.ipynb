{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FRB Type-IV vs Type-IV Classification \n",
    "\n",
    "This notebook explores CNN-based classification of simulated\n",
    "type IV and type V morphology of the FRBs as described in the Kumar et. al. 2025\n",
    "\n",
    "## Notes\n",
    "- Training data is generated using simulation scripts in the folder frabjous_sim.\n",
    "- This notebook is used  to obtain the hyperparameter optimised models.\n",
    "- the type IV here is refered to as type C1 \n",
    "- the tyoe V here is refered to as type C2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "from sklearn.metrics import  ConfusionMatrixDisplay\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import locale\n",
    "import time\n",
    "import datetime\n",
    "import json \n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import keras.layers as KL\n",
    "import keras.models as KM\n",
    "import keras.optimizers as KO\n",
    "import keras.callbacks as KC\n",
    "import keras.utils as KU\n",
    "import keras.preprocessing.image as KI\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Concatenate,Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D \n",
    "from keras.models import Model\n",
    "import keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_indices(fname):\n",
    "    indices = []\n",
    "    with open(SIMFRB_DIR / fname) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                indices.append(int(line))\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(type1, type2, snr, remove_indices_C1, remove_indices_C2):\n",
    "    \"\"\"\n",
    "    Load Simulated FRB 2-D dynamic spectra and labels for two archetypes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    type1, type2 : str\n",
    "        FRB morphology labels (e.g., 'B', 'C1').\n",
    "    snr : str\n",
    "        Signal-to-noise ratio label (e.g., '50').\n",
    "    remove_indices_C1 : list of int\n",
    "        Indices of simulated FRBs to exclude for type1.\n",
    "    remove_indices_C2 : list of int\n",
    "        Indices of simulated FRBs to exclude for type2.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    labels : list\n",
    "        Binary class labels.\n",
    "    images : list\n",
    "        Normalized 2D FRB dynamic spectra.\n",
    "    \"\"\"\n",
    "\n",
    "    base_path = os.path.join(BASE_DIR, \"simfrb\", \"simdata\", \"type_\")\n",
    "\n",
    "    # ---- Load metadata ----\n",
    "    with open(f\"{base_path}{type1}/SNR_{snr}/frb_header_type_{type1}.json\") as f:\n",
    "        class1_labels = json.load(f)\n",
    "\n",
    "    with open(f\"{base_path}{type2}/SNR_{snr}/frb_header_type_{type2}.json\") as f:\n",
    "        class2_labels = json.load(f)\n",
    "\n",
    "    # ---- Load image data ----\n",
    "    frbd1 = np.load(\n",
    "        f\"{base_path}{type1}/SNR_{snr}/simulatefrbs_type_{type1}.npz\"\n",
    "    )[\"arr_0\"]\n",
    "\n",
    "    frbd2 = np.load(\n",
    "        f\"{base_path}{type2}/SNR_{snr}/simulatefrbs_type_{type2}.npz\"\n",
    "    )[\"arr_0\"]\n",
    "\n",
    "    frbdn = []\n",
    "    frbdl = []\n",
    "    frbdm = []\n",
    "    frbdi = []\n",
    "\n",
    "    for i in range(len(frbd1)):\n",
    "        if i in remove_indices_C1:\n",
    "            continue\n",
    "\n",
    "        immax = frbd1[i].max()\n",
    "        frbdn.append(frbd1[i] / (immax / 255))\n",
    "        frbdl.append(0)\n",
    "        frbdm.append(immax)\n",
    "        frbdi.append(i)\n",
    "\n",
    "    for i in range(len(frbd2)):\n",
    "        if i in remove_indices_C2:\n",
    "            continue\n",
    "\n",
    "        immax = frbd2[i].max()\n",
    "        frbdn.append(frbd2[i] / (immax / 255))\n",
    "        frbdl.append(1)\n",
    "        frbdm.append(immax)\n",
    "        frbdi.append(i)\n",
    "\n",
    "    return frbdl, frbdn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type1 = 'C1'\n",
    "type2 = 'C2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Data Directory Structure\n",
    "\n",
    "\n",
    "<pre>\n",
    "&lt;BASE_DIR&gt;/\n",
    "├── simfrb/\n",
    "│   ├── simdata/\n",
    "│   │   ├── type_C1/\n",
    "│   │   │   ├── SNR_15/\n",
    "│   │   │   ├── SNR_25/\n",
    "│   │   │   ├── SNR_35/\n",
    "│   │   │   ├── SNR_50/\n",
    "│   │   │   └── SNR_100/\n",
    "│   │   └── type_C2/\n",
    "│   │       ├── SNR_15/\n",
    "│   │       ├── SNR_25/\n",
    "│   │       ├── SNR_35/\n",
    "│   │       ├── SNR_50/\n",
    "│   │       └── SNR_100/\n",
    "</pre>\n",
    "\n",
    "### Notes\n",
    "- `type C1` corresponds to **Type IV FRBs**\n",
    "- `type C2` corresponds to **Type V FRBs**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.experimental.enable_tf_random_generator()\n",
    "tf.keras.utils.set_random_seed(1334534)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR='/media/akumar/Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMFRB_DIR = Path(BASE_DIR) / \"simfrb\"\n",
    "\n",
    "#### loading the indices for type C1 samples to exlude from training data #######\n",
    "remove_indices_C1_100 = read_indices(\"remove_type_C1_SNR_100.txt\")\n",
    "remove_indices_C1_50  = read_indices(\"remove_type_C1_SNR_50.txt\")\n",
    "remove_indices_C1_35  = read_indices(\"remove_type_C1_SNR_35.txt\")\n",
    "remove_indices_C1_25  = read_indices(\"remove_type_C1_SNR_25.txt\")\n",
    "\n",
    "indices_C1_15 = read_indices(\"type_C1_SNR_15.txt\")\n",
    "remove_indices_C1_15 = [x for x in np.arange(0, 1000) if x not in indices_C1_15]\n",
    "\n",
    "\n",
    "#### loading the indices for type C2 samples to exlude from training data #######\n",
    "remove_indices_C2_100 = read_indices(\"type_C2_SNR_100.txt\")\n",
    "remove_indices_C2_50  = read_indices(\"type_C2_SNR_50.txt\")\n",
    "remove_indices_C2_35  = read_indices(\"type_C2_SNR_35.txt\")\n",
    "remove_indices_C2_25  = read_indices(\"type_C2_SNR_25.txt\")\n",
    "\n",
    "indices_C2_15 = read_indices(\"type_C2_SNR_15.txt\")\n",
    "remove_indices_C2_15 = [x for x in np.arange(0, 1000) if x not in indices_C2_15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frbdl, frbdn = read_data(type1, type2, '100', remove_indices_C1_100, remove_indices_C2_100)\n",
    "\n",
    "temp_labels, temp_data = read_data(type1, type2, '50', remove_indices_C1_50, remove_indices_C2_50)\n",
    "frbdl = frbdl + temp_labels\n",
    "frbdn = frbdn + temp_data\n",
    "\n",
    "temp_labels, temp_data = read_data(type1, type2, '35', remove_indices_C1_35, remove_indices_C2_35)\n",
    "frbdl = frbdl + temp_labels\n",
    "frbdn = frbdn + temp_data\n",
    "\n",
    "temp_labels, temp_data = read_data(type1, type2, '25', remove_indices_C1_25, remove_indices_C2_25)\n",
    "frbdl = frbdl + temp_labels\n",
    "frbdn = frbdn + temp_data\n",
    "\n",
    "temp_labels, temp_data = read_data(type1, type2, '15', remove_indices_C1_15, remove_indices_C2_15)\n",
    "frbdl = frbdl + temp_labels\n",
    "frbdn = frbdn + temp_data\n",
    "\n",
    "frbdn = np.asarray(frbdn)\n",
    "frbdn.shape += (1,)\n",
    "frbdl = np.asarray(frbdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (frbdn.shape[1] , frbdn.shape[2],1)\n",
    "split = train_test_split(frbdl, frbdn, test_size=0.15, random_state=42)\n",
    "(trainAttrX, testingAttrX, trainImagesX, testingImagesX) = split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = train_test_split(trainAttrX, trainImagesX, test_size=0.2, random_state=42)\n",
    "(trainAttrX, testAttrX, trainImagesX, testImagesX) = split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainAttrX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(testingAttrX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    \"\"\"\n",
    "    Build a CNN model based in the input hyperparameters\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    hp : keras_tuner.HyperParameters\n",
    "        Hyperparameter object for tuning model configuration.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : keras.Model\n",
    "        Compiled Keras model.\n",
    "    \"\"\"\n",
    "\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    ######    CNN layers  #########\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    ###### fully connected layers #######\n",
    "    model.add(\n",
    "        Dense(\n",
    "            units=hp.Choice(\"units_1\", values=[16, 32, 64]),\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        Dropout(\n",
    "            hp.Choice(\"dropout1\", values=[0.15, 0.2, 0.25, 0.3])\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        Dense(\n",
    "            units=hp.Choice(\"units_2\", values=[4, 8, 16, 32]),\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        Dropout(\n",
    "            hp.Choice(\"dropout2\", values=[0.15, 0.2, 0.25, 0.3])\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # ---- Output layer ----\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    ###### Optimizer hyperparameters #####\n",
    "    learning_rate = hp.Choice(\n",
    "        \"learning_rate\", values=[2e-4, 5e-4, 1e-5, 2e-5, 5e-5]\n",
    "    )\n",
    "\n",
    "    # Batch size is tuned externally during training\n",
    "    hp.Choice(\"batch_size\", values=[32, 64, 128])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hp = keras_tuner.HyperParameters()\n",
    "model_builder(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = hp.Choice( 'batch_size' , values=[ 32 , 64, 128 ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=model_builder,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=100,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=os.path.join(BASE_DIR, \"model_tuning_c1_c2\")\n",
    "    project_name=\"classify_c1_c2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=os.path.join(BASE_DIR, \"model_tuning_c1_c2\", \"tensorboard_logs\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.search( x= trainImagesX, y=trainAttrX, epochs = 300, validation_data=(testImagesX, testAttrX)  , callbacks= [stop_early,tensorboard ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=10)\n",
    "best_model = models[0]\n",
    "\n",
    "# Explicitly build the model to enable summary display\n",
    "best_model.build(input_shape=(None, 256, 256, 1))\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    models[i].save('/path/to/directory/best_model_' + str(i), save_format ='tf')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_model.predict(testingImagesX)\n",
    "predictions_bool = (predictions > 0.5)\n",
    "cm_1 = confusion_matrix( testingAttrX , predictions_bool, labels=[0 , 1])\n",
    "cm_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = best_model.evaluate(testingImagesX, testingAttrX, verbose=2 )\n",
    "f1score = f1_score(testingAttrX, predictions_bool)\n",
    "print(round(acc ,4), round(f1score,4 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(testingAttrX, predictions)\n",
    "####Plotting the FPR-FNR curve for the best model\n",
    "plt.rc('font', size=10)\n",
    "plt.plot(np.flip(thresholds[1:]), np.flip(fpr[1:])*100,label='False Positive Rate')\n",
    "plt.plot(np.flip(thresholds[1:]), np.flip(1-tpr[1:])*100,label='False Negative Rate')\n",
    "plt.xlabel('Threshold',fontsize = 20)\n",
    "plt.ylabel('Cumulative percentage',fontsize = 10)\n",
    "plt.title('FPR FNR vs threshold ',fontsize = 10)\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.grid(True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
