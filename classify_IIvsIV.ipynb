{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FRB Type-II vs Type-IV Classification \n",
    "\n",
    "This notebook explores CNN-based classification of simulated\n",
    "type II and type IV morphology of the FRBs as described in the Kumar et. al. 2025\n",
    "\n",
    "## Notes\n",
    "- Training data is generated using simulation scripts in the folder frabjous_sim.\n",
    "- This notebook is used  to obtain the hyperparameter optimised models.\n",
    "- the type II here is refered to as type B \n",
    "- the tyoe IV here is refered to as type C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "from sklearn.metrics import  ConfusionMatrixDisplay\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import locale\n",
    "import time\n",
    "import datetime\n",
    "import json \n",
    "import glob\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import keras.layers as KL\n",
    "import keras.models as KM\n",
    "import keras.optimizers as KO\n",
    "import keras.callbacks as KC\n",
    "import keras.utils as KU\n",
    "import keras.preprocessing.image as KI\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Concatenate,Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D \n",
    "from keras.models import Model\n",
    "import keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type1 = 'B'\n",
    "type2 = 'C1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.experimental.enable_tf_random_generator()\n",
    "tf.keras.utils.set_random_seed(1334534)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This is base directory where you will keep the generated FRB samples\n",
    "\n",
    "BASE_DIR = os.getenv(\"base_directory\", \"/DATA/ajay/\")\n",
    "\n",
    "print(f\"Using BASE_DIR = {BASE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Data Directory Structure\n",
    "\n",
    "<BASE_DIR>/\n",
    "├── simfrb/\n",
    "│ ├── simdata/\n",
    "│ │ ├── type_B/\n",
    "│ │ │ ├── SNR_15/\n",
    "│ │ │ ├── SNR_25/\n",
    "│ │ │ ├── SNR_35/\n",
    "│ │ │ ├── SNR_50/\n",
    "│ │ │ └── SNR_100/\n",
    "│ │ └── type_C1/\n",
    "│ │ ├── SNR_15/\n",
    "│ │ ├── SNR_25/\n",
    "│ │ ├── SNR_35/\n",
    "│ │ ├── SNR_50/\n",
    "│ │ └── SNR_100/\n",
    "│ ├── remove_SNR_100/\n",
    "│ ├── remove_type_C1_SNR_50.txt\n",
    "│ ├── remove_type_C1_SNR_35.txt\n",
    "│ ├── remove_type_C1_SNR_25.txt\n",
    "│ └── type_C1_SNR_15.txt\n",
    "\n",
    "Each 'SNR_xx/' directory contains:\n",
    "- `simulatefrbs_type_<TYPE>.npz` : simulated FRB dynamic spectra\n",
    "- `frb_header_type_<TYPE>.json` : corresponding metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### We identified several examples in type C1 which look like single component\n",
    "### These examples are then filtered out from the training dataset \n",
    "\n",
    "SIMFRB_BASEDIR = os.path.join(BASE_DIR, \"simfrb\")\n",
    "\n",
    "def load_indices_from_txt(filepath):\n",
    "    \"\"\"Load integer indices from a text file.\"\"\"\n",
    "    with open(filepath, \"r\") as f:\n",
    "        return [int(line.strip()) for line in f if line.strip()]\n",
    "\n",
    "# SNR = 100\n",
    "remove_indices_100 = [\n",
    "    int(os.path.basename(f).split(\"_\")[-1].split(\".\")[0])\n",
    "    for f in glob.glob(os.path.join(SIMFRB_BASEDIR, \"remove_SNR_100\", \"*\"))\n",
    "]\n",
    "\n",
    "# SNR = 50\n",
    "remove_indices_50 = load_indices_from_txt(\n",
    "    os.path.join(SIMFRB_BASEDIR, \"remove_type_C1_SNR_50.txt\")\n",
    ")\n",
    "\n",
    "# SNR = 35\n",
    "remove_indices_35 = load_indices_from_txt(\n",
    "    os.path.join(SIMFRB_BASEDIR, \"remove_type_C1_SNR_35.txt\")\n",
    ")\n",
    "\n",
    "# SNR = 25\n",
    "remove_indices_25 = load_indices_from_txt(\n",
    "    os.path.join(SIMFRB_BASEDIR, \"remove_type_C1_SNR_25.txt\")\n",
    ")\n",
    "\n",
    "# SNR = 15 \n",
    "indices_15 = load_indices_from_txt(\n",
    "    os.path.join(SIMFRB_BASEDIR, \"type_C1_SNR_15.txt\")\n",
    ")\n",
    "remove_indices_15 = list(set(np.arange(0, 1000)) - set(indices_15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_data(type1,type2,snr,remove_indices):\n",
    "    \"\"\"\n",
    "    Load simulated FRB images and labels for two morphology classes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    type1, type2 : str\n",
    "        FRB morphology labels (e.g., 'B', 'C1').\n",
    "    snr : str\n",
    "        Signal-to-noise ratio label (e.g., '50').\n",
    "    remove_indices : list of int\n",
    "        Indices of simulated FRBs to exclude (applied to type2 only).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    labels : list\n",
    "        Binary class labels.\n",
    "    images : list\n",
    "        Normalized 2D FRB dynamic spectra.\n",
    "    \"\"\"\n",
    "\n",
    "    base_path = os.path.join(BASE_DIR, \"simfrb\", \"simdata\", \"type_\")\n",
    "\n",
    "    # ---- Load metadata ----\n",
    "    with open(f\"{base_path}{type1}/SNR_{snr}/frb_header_type_{type1}.json\") as f:\n",
    "        class1_labels = json.load(f)\n",
    "\n",
    "    with open(f\"{base_path}{type2}/SNR_{snr}/frb_header_type_{type2}.json\") as f:\n",
    "        class2_labels = json.load(f)\n",
    "\n",
    "    # ---- Load image data ----\n",
    "    frbd1 = np.load(\n",
    "        f\"{base_path}{type1}/SNR_{snr}/simulatefrbs_type_{type1}.npz\"\n",
    "    )[\"arr_0\"]\n",
    "\n",
    "    frbd2 = np.load(\n",
    "        f\"{base_path}{type2}/SNR_{snr}/simulatefrbs_type_{type2}.npz\"\n",
    "    )[\"arr_0\"]\n",
    "           \n",
    "    frbdn = []\n",
    "    frbdl = []\n",
    "    frbdm = []\n",
    "    frbdi = []\n",
    "    for i in range(0,len(frbd2)):\n",
    "            if i in remove_indices : \n",
    "                continue\n",
    "            else :\n",
    "                immax = frbd1[i].max() \n",
    "                frbdn.append(frbd1[i]/(immax/255))\n",
    "                frbdl.append(0)\n",
    "                frbdm.append(immax)\n",
    "                frbdi.append(i)\n",
    "\n",
    "                immax = frbd2[i].max()\n",
    "                frbdn.append(frbd2[i]/(immax/255))\n",
    "                frbdl.append(1)\n",
    "                frbdm.append(immax)\n",
    "                frbdi.append(i)\n",
    "\n",
    "    return frbdl,frbdn \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "frbdl,frbdn ,test_data_100, test_label_100 ,frb_params_100= read_data(type1,type2,'100',remove_indices_100)\n",
    "frbdl = frbdl[:]\n",
    "frbdn = frbdn[:]\n",
    "temp1,temp2 ,test_data_50, test_label_50 ,frb_params_50= read_data(type1,type2,'50',remove_indices_50)\n",
    "frbdl = frbdl + temp1[:]\n",
    "frbdn = frbdn + temp2[:]\n",
    "temp1,temp2 ,test_data_35, test_label_35 ,frb_params_35= read_data(type1,type2,'35',remove_indices_35)\n",
    "frbdl = frbdl + temp1[:]\n",
    "frbdn = frbdn + temp2[:]\n",
    "temp1,temp2 ,test_data_25, test_label_25 , frb_params_25= read_data(type1,type2,'25',remove_indices_25)\n",
    "frbdl = frbdl + temp1[:]\n",
    "frbdn = frbdn + temp2[:]\n",
    "temp1, temp2, test_data_15, test_label_15, frb_params_15 = read_data(type1,type2,'15',remove_indices_15)\n",
    "frbdl = frbdl + temp1[:]\n",
    "frbdn = frbdn + temp2[:]\n",
    "\n",
    "frbdn = np.asarray(frbdn)     \n",
    "frbdn.shape += 1,\n",
    "frbdl = np.asarray(frbdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_shape = (frbdn.shape[1] , frbdn.shape[2],1)\n",
    "split = train_test_split(frbdl, frbdn, test_size=0.15, random_state=42)\n",
    "(trainAttrX, testingAttrX, trainImagesX, testingImagesX) = split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = train_test_split(trainAttrX, trainImagesX, test_size=0.2, random_state=42)\n",
    "(trainAttrX, testAttrX, trainImagesX, testImagesX) = split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    \"\"\"\n",
    "    CNN based model builder for hyperparameter tuning\n",
    "    \"\"\"\n",
    "\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    ######    CNN layers  #########\n",
    "    model.add(Conv2D(32, (3, 3), activation=\"relu\",\n",
    "                     input_shape=(256, 256, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (5, 5), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    ###### fully connected layers #######\n",
    "    model.add(\n",
    "        Dense(\n",
    "            units=hp.Choice(\"units_1\", values=[16, 32, 64]),\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        Dropout(\n",
    "            hp.Choice(\"dropout1\", values=[0.15, 0.2, 0.25, 0.3])\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        Dense(\n",
    "            units=hp.Choice(\"units_2\", values=[4, 8, 16, 32]),\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        Dropout(\n",
    "            hp.Choice(\"dropout2\", values=[0.15, 0.2, 0.25, 0.3])\n",
    "        )\n",
    "    )\n",
    "\n",
    "    \n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    ###### Optimizer hyperparameters #####\n",
    "    hp_learning_rate = hp.Choice(\n",
    "        \"learning_rate\",\n",
    "        values=[2e-4, 5e-4, 1e-5, 2e-5, 5e-5],\n",
    "    )\n",
    "\n",
    "    # Batch size is tuned at the training stage, not inside the model\n",
    "    hp.Choice(\"batch_size\", values=[32, 64, 128])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            learning_rate=hp_learning_rate\n",
    "        ),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hp = keras_tuner.HyperParameters()\n",
    "model_builder(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = hp.Choice( 'batch_size' , values=[ 32 , 64, 128 ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=model_builder,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=100,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=\"/DATA/ajay/ML_training/tuning_model_B_C1\",\n",
    "    project_name=\"version3_equal_weights\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard  = keras.callbacks.TensorBoard('/DATA/ajay/ML_training/tuning_model_B_C1/version3_equal_weights/tb_logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.search( x= trainImagesX, y=trainAttrX, epochs = 200, validation_data=(testImagesX, testAttrX)  , callbacks= [stop_early,tensorboard ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=10)\n",
    "best_model = models[0]\n",
    "# Build the model.\n",
    "best_model.build(input_shape=(None, 28, 28)) \n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=10)\n",
    "#print(type(models[0]))\n",
    "#models[0].save('/DATA/ajay/ML_training/tuning_model/best_model_' + str(0) )\n",
    "best_model = models[0]\n",
    "for i in range(0,10):\n",
    "    models[i].save('/path/to/directory/best_model_' + str(i), save_format ='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(5)\n",
    "##\n",
    "model = model_builder(best_hps[0])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing with the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = train_test_split(frbdl, frbdn, test_size=0.15, random_state=42)\n",
    "(trainAttrX, testingAttrX, trainImagesX, testingImagesX) = split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_model.predict(testingImagesX)\n",
    "predictions_bool = (predictions > 0.5)\n",
    "cm_1 = confusion_matrix( testingAttrX , predictions_bool, labels=[0 , 1])\n",
    "cm_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = best_model.evaluate(testingImagesX, testingAttrX, verbose=2 )\n",
    "f1score = f1_score(testingAttrX, predictions_bool)\n",
    "print(round(acc ,4), round(f1score,4 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(testingAttrX, predictions)\n",
    "####Plotting the FPR-FNR curve for the best model\n",
    "plt.rc('font', size=10)\n",
    "plt.plot(np.flip(thresholds[1:]), np.flip(fpr[1:])*100,label='False Positive Rate')\n",
    "plt.plot(np.flip(thresholds[1:]), np.flip(1-tpr[1:])*100,label='False Negative Rate')\n",
    "plt.xlabel('Threshold',fontsize = 20)\n",
    "plt.ylabel('Cumulative percentage',fontsize = 10)\n",
    "plt.title('FPR FNR vs threshold ',fontsize = 10)\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "#plt.setp(ax4.get_xticklabels(), fontsize=15)\n",
    "#plt.setp(ax4.get_yticklabels(), fontsize=15)    \n",
    "plt.grid(True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
