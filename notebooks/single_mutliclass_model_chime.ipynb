{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82fe2e6e",
   "metadata": {},
   "source": [
    "### FRB classification of all types of morphology \n",
    "\n",
    "This notebook explores CNN-based classification of multiple classes:\n",
    "type A (I), type B (II), type C (III), type C1 (IV) and type C2 (V) morphology of the FRBs as described in Kumar et al. 2025\n",
    "\n",
    "### Notes\n",
    "- Training data is generated using simulation scripts in the folder frabjous_sim.\n",
    "- This notebook is used  to obtain the hyperparameter optimised models.\n",
    "- the type I here is refered to as type A \n",
    "- the type II here is refered to as type B\n",
    "- the type II here is refered to as type C\n",
    "- the type IV here is refered to as type C1\n",
    "- the type V here is refered to as type C2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8f3f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "from sklearn.metrics import  ConfusionMatrixDisplay\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import locale\n",
    "import time\n",
    "import datetime\n",
    "import json \n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import keras.layers as KL\n",
    "import keras.models as KM\n",
    "import keras.optimizers as KO\n",
    "import keras.callbacks as KC\n",
    "import keras.utils as KU\n",
    "import keras.preprocessing.image as KI\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Concatenate,Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D \n",
    "from keras.models import Model\n",
    "import keras_tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875deebf",
   "metadata": {},
   "source": [
    "You can either generate your own simulated dataset using the scripts in `frabjous_sim/` or download a prepared archive:\n",
    "\n",
    "Download: https://drive.google.com/file/d/1gABgy59nyHcNOffODCyzDRfNvvt4t29B/view?usp=drive_link\n",
    "\n",
    "After downloading, unzip the archive so the `simfrb/` directory appears under `BASE_DIR`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e7bd4a",
   "metadata": {},
   "source": [
    "### Expected Data Directory Structure\n",
    "\n",
    "<pre>\n",
    "&lt;BASE_DIR&gt;/\n",
    "├── simfrb/\n",
    "│   ├── simdata/\n",
    "│   │   ├── type_A/\n",
    "│   │   │   ├── SNR_15/\n",
    "│   │   │   ├── SNR_25/\n",
    "│   │   │   ├── SNR_35/\n",
    "│   │   │   ├── SNR_50/\n",
    "│   │   │   └── SNR_100/\n",
    "│   │   └── type_B/\n",
    "│   │       ├── SNR_15/\n",
    "│   │       ├── SNR_25/\n",
    "│   │       ├── SNR_35/\n",
    "│   │       ├── SNR_50/\n",
    "│   │       └── SNR_100/\n",
    "|   |   .\n",
    "|   |   .\n",
    "|   |   .\n",
    "</pre>\n",
    "\n",
    "### Notes\n",
    "- If you don't have simulated data, you can download the prepared dataset (see the next cell).\n",
    "- Place the unzipped `simfrb` folder under `BASE_DIR` so the data-loading helpers find files automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f881de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type1, type2, type3, type4, type5 define the five morphology labels used throughout the notebook (e.g., type1 = 'A', type2 = 'B', etc.).\n",
    "# These variables are used by the data-loading functions to construct file paths to locate the corresponding `.npz` and `.json` files.\n",
    "# Changing these values will change which classes are loaded for training, validation, and testing.\n",
    "type1 = 'A'\n",
    "type2 = 'B'\n",
    "type3 = 'C'\n",
    "type4 = 'C1'\n",
    "type5 = 'C2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11569d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.experimental.enable_tf_random_generator()\n",
    "tf.keras.utils.set_random_seed(1354534)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b992e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the simulation data directory\n",
    "SIMFRB_DIR = Path(BASE_DIR) / \"simfrb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d902a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read indices from a file\n",
    "def read_indices(fname):\n",
    "    indices = []\n",
    "    with open(SIMFRB_DIR / fname) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                indices.append(int(line))\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f367584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read simulated FRB images for all five classes for a given SNR and apply removal indices\n",
    "def read_data(snr, remove_indices_C1, remove_indices_C2):\n",
    "    \"\"\"\n",
    "    Load simulated FRB 2-D dynamic spectra and labels for multiple archetypes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    snr : str\n",
    "        Signal-to-noise ratio label (e.g., '50').\n",
    "    remove_indices_C1 : list of int\n",
    "        Indices of simulated FRBs to exclude for class C1.\n",
    "    remove_indices_C2 : list of int\n",
    "        Indices of simulated FRBs to exclude for class C2.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    labels : list\n",
    "        One-hot labels for the multiclass problem.\n",
    "    images : list\n",
    "        Normalized 2D FRB dynamic spectra.\n",
    "    \"\"\"\n",
    "\n",
    "    base_path = os.path.join(BASE_DIR, \"simfrb\", \"simdata\", \"type_\")\n",
    "\n",
    "    # ---- Load metadata ----\n",
    "    with open(f\"{base_path}{type1}/SNR_{snr}/frb_header_type_{type1}.json\") as f:\n",
    "        class1_labels = json.load(f)\n",
    "\n",
    "    with open(f\"{base_path}{type2}/SNR_{snr}/frb_header_type_{type2}.json\") as f:\n",
    "        class2_labels = json.load(f)\n",
    "\n",
    "    # ---- Load image data ----\n",
    "    frbd1 = np.load(\n",
    "        f\"{base_path}{type1}/SNR_{snr}/simulatefrbs_type_{type1}.npz\"\n",
    "    )[\"arr_0\"]\n",
    "\n",
    "    frbd2 = np.load(\n",
    "        f\"{base_path}{type2}/SNR_{snr}/simulatefrbs_type_{type2}.npz\"\n",
    "    )[\"arr_0\"]\n",
    "\n",
    "    frbd3 = np.load(\n",
    "        f\"{base_path}{type3}/SNR_{snr}/simulatefrbs_type_{type3}.npz\"\n",
    "    )[\"arr_0\"]\n",
    "\n",
    "    frbd4 = np.load(\n",
    "        f\"{base_path}{type4}/SNR_{snr}/simulatefrbs_type_{type4}.npz\"\n",
    "    )[\"arr_0\"]\n",
    "\n",
    "    frbd5 = np.load(\n",
    "        f\"{base_path}{type5}/SNR_{snr}/simulatefrbs_type_{type5}.npz\"\n",
    "    )[\"arr_0\"]\n",
    "\n",
    "    frbdn = []\n",
    "    frbdl = []\n",
    "\n",
    "    for i in range(len(frbd1)):\n",
    "        if i in remove_indices_C1:\n",
    "            continue\n",
    "        else:\n",
    "            immax = frbd1[i].max() \n",
    "            frbdn.append(frbd1[i]/(immax/255))\n",
    "            frbdl.append([1.,0.,0.,0.,0.])\n",
    "\n",
    "            immax = frbd2[i].max()\n",
    "            frbdn.append(frbd2[i]/(immax/255))\n",
    "            frbdl.append([0.,1.,0.,0.,0.])\n",
    "\n",
    "            immax = frbd3[i].max()\n",
    "            frbdn.append(frbd3[i]/(immax/255))\n",
    "            frbdl.append([0.,0.,1.,0.,0.])\n",
    "                            \n",
    "            immax = frbd4[i].max()\n",
    "            frbdn.append(frbd4[i]/(immax/255))\n",
    "            frbdl.append([0.,0.,0.,1.,0.])\n",
    "\n",
    "    for i in range(len(frbd5)):\n",
    "        if i in remove_indices_C2:\n",
    "            continue\n",
    "        else:\n",
    "            immax = frbd5[i].max()\n",
    "            frbdn.append(frbd5[i]/(immax/255))\n",
    "            frbdl.append([0.,0.,0.,0.,1.])\n",
    "\n",
    "    return frbdl, frbdn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32830d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to  Load CHIME FRB images and correct labels (interpolated examples).\n",
    "def read_chime_data(data_file, label_file):\n",
    "    \"\"\"\n",
    "    Reads interpolated CHIME FRB dynamic spectra and label file,\n",
    "    normalizes images and returns per-class train/test splits.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_file : str\n",
    "        Path to the NumPy `.npz` file containing FRB images (arr_0).\n",
    "    label_file : str\n",
    "        Path to a text file containing morphology labels (one per line: A, B, C, C1, or C2).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    labels_train, images_train, labels_test, images_test\n",
    "    \"\"\"\n",
    "\n",
    "    # Containers for each morphology class\n",
    "    frbdn1, frbdn2, frbdn3, frbdn4, frbdn5 = [], [], [], [], []\n",
    "    frbdl1, frbdl2, frbdl3, frbdl4, frbdl5 = [], [], [], [], []\n",
    "\n",
    "    # ---- Load data ----\n",
    "    with np.load(data_file) as frbdata:\n",
    "        frbd = frbdata[\"arr_0\"]\n",
    "\n",
    "    with open(label_file) as f:\n",
    "        correct_type = f.readlines()\n",
    "\n",
    "    # ---- Assign images and labels ----\n",
    "    for i in range(len(correct_type)):\n",
    "        immax = frbd[i].max()\n",
    "        norm_img = frbd[i] / (immax / 255)\n",
    "\n",
    "        if correct_type[i] == \"A\\n\":\n",
    "            frbdn1.append(norm_img)\n",
    "            frbdl1.append([1., 0., 0., 0., 0.])\n",
    "\n",
    "        if correct_type[i] == \"B\\n\":\n",
    "            frbdn2.append(norm_img)\n",
    "            frbdl2.append([0., 1., 0., 0., 0.])\n",
    "\n",
    "        if correct_type[i] == \"C\\n\":\n",
    "            frbdn3.append(norm_img)\n",
    "            frbdl3.append([0., 0., 1., 0., 0.])\n",
    "\n",
    "        if correct_type[i] == \"C1\\n\":\n",
    "            frbdn4.append(norm_img)\n",
    "            frbdl4.append([0., 0., 0., 1., 0.])\n",
    "\n",
    "        if correct_type[i] == \"C2\\n\":\n",
    "            frbdn5.append(norm_img)\n",
    "            frbdl5.append([0., 0., 0., 0., 1.])\n",
    "\n",
    "    # ---- Train / test split (per class) ----\n",
    "    lenA  = int(len(frbdn1) / 2)\n",
    "    lenB  = int(len(frbdn2) / 2)\n",
    "    lenC  = int(len(frbdn3) / 2)\n",
    "    lenC1 = int(len(frbdn4) / 2)\n",
    "    lenC2 = int(len(frbdn5) / 2)\n",
    "\n",
    "    images_train = (\n",
    "        frbdn1[:lenA] +\n",
    "        frbdn2[:lenB] +\n",
    "        frbdn3[:lenC] +\n",
    "        frbdn4[:lenC1] +\n",
    "        frbdn5[:lenC2]\n",
    "    )\n",
    "\n",
    "    labels_train = (\n",
    "        frbdl1[:lenA] +\n",
    "        frbdl2[:lenB] +\n",
    "        frbdl3[:lenC] +\n",
    "        frbdl4[:lenC1] +\n",
    "        frbdl5[:lenC2]\n",
    "    )\n",
    "\n",
    "    images_test = (\n",
    "        frbdn1[lenA:] +\n",
    "        frbdn2[lenB:] +\n",
    "        frbdn3[lenC:] +\n",
    "        frbdn4[lenC1:] +\n",
    "        frbdn5[lenC2:]\n",
    "    )\n",
    "\n",
    "    labels_test = (\n",
    "        frbdl1[lenA:] +\n",
    "        frbdl2[lenB:] +\n",
    "        frbdl3[lenC:] +\n",
    "        frbdl4[lenC1:] +\n",
    "        frbdl5[lenC2:]\n",
    "    )\n",
    "\n",
    "    return labels_train, images_train,  labels_test, images_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e017e83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load removal index files for C1 (type IV) examples that should be excluded from training\n",
    "remove_indices_C1_100 = read_indices(\"remove_type_C1_SNR_100.txt\")\n",
    "remove_indices_C1_50  = read_indices(\"remove_type_C1_SNR_50.txt\")\n",
    "remove_indices_C1_35  = read_indices(\"remove_type_C1_SNR_35.txt\")\n",
    "remove_indices_C1_25  = read_indices(\"remove_type_C1_SNR_25.txt\")\n",
    "indices_C1_15 = read_indices(\"type_C1_SNR_15.txt\")\n",
    "remove_indices_C1_15 = [x for x in np.arange(0, 1000) if x not in indices_C1_15]\n",
    "\n",
    "# Load indices for C2 (type V) examples to exclude\n",
    "remove_indices_C2_100 = read_indices(\"type_C2_SNR_100.txt\")\n",
    "remove_indices_C2_50  = read_indices(\"type_C2_SNR_50.txt\")\n",
    "remove_indices_C2_35  = read_indices(\"type_C2_SNR_35.txt\")\n",
    "remove_indices_C2_25  = read_indices(\"type_C2_SNR_25.txt\")\n",
    "indices_C2_15 = read_indices(\"type_C2_SNR_15.txt\")\n",
    "remove_indices_C2_15 = [x for x in np.arange(0, 1000) if x not in indices_C2_15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436d4e8b",
   "metadata": {},
   "source": [
    "Loading the training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507f1c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load simulated data at multiple SNR levels and combine them\n",
    "# SNR_100\n",
    "frbdl, frbdn = read_data('100', remove_indices_C1_100, remove_indices_C2_100)\n",
    "\n",
    "# SNR_50\n",
    "temp_labels, temp_data = read_data('50', remove_indices_C1_50, remove_indices_C2_50)\n",
    "frbdl = frbdl + temp_labels[:]\n",
    "frbdn = frbdn + temp_data[:]\n",
    "\n",
    "# SNR_35\n",
    "temp_labels, temp_data = read_data('35', remove_indices_C1_35, remove_indices_C2_35)\n",
    "frbdl = frbdl + temp_labels[:]\n",
    "frbdn = frbdn + temp_data[:]\n",
    "\n",
    "# SNR_25\n",
    "temp_labels, temp_data = read_data('25', remove_indices_C1_25, remove_indices_C2_25)\n",
    "frbdl = frbdl + temp_labels[:]\n",
    "frbdn = frbdn + temp_data[:]\n",
    "\n",
    "# SNR_15\n",
    "temp_labels, temp_data = read_data('15', remove_indices_C1_15, remove_indices_C2_15)\n",
    "frbdl = frbdl + temp_labels[:]\n",
    "frbdn = frbdn + temp_data[:]\n",
    "\n",
    "# reading the chime data\n",
    "## chime bursts with interpolation and their label file are provided in the directory\n",
    "chime_labels, chime_data, chime_test_labels, chime_test = read_chime_data('files/chime_interp_frbs.npz','files/chime_labels.txt')\n",
    "frbdl = frbdl + chime_labels[:]\n",
    "frbdn = frbdn + chime_data[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7914587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "frbdn = np.asarray(frbdn)     \n",
    "frbdn.shape += 1,\n",
    "frbdl = np.asarray(frbdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae4b22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into train and test sets\n",
    "split = train_test_split(frbdl, frbdn, test_size=0.20, random_state=42)\n",
    "(trainAttrX, testingAttrX, trainImagesX, testingImagesX) = split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2d75a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the training set further into train and validation sets\n",
    "split = train_test_split(trainAttrX, trainImagesX, test_size=0.2, random_state=42)\n",
    "(trainAttrX, testAttrX, trainImagesX, testImagesX) = split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec5eedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fuction to build model which is used for training and hyperparameter tuning\n",
    "\n",
    "def model_builder(hp):\n",
    "    \"\"\"\n",
    "    Build a 2D CNN classifier for FRB morphology classification.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    hp : keras_tuner.HyperParameters\n",
    "        Hyperparameter object used by Keras Tuner.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : keras.Model\n",
    "        Compiled Keras model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Input\n",
    "    input_2d = Input(shape=(256, 256, 1))\n",
    "\n",
    "    # CNN layers \n",
    "    x = Conv2D(filters=32, kernel_size=3, activation='relu')(input_2d)\n",
    "    x = MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "    x = Conv2D(filters=32, kernel_size=3, activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "    x = Conv2D(filters=32, kernel_size=3, activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=5)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # Fully connected layers \n",
    "    x = Dense(\n",
    "        units=hp.Choice(\"units_1\", values=[64, 128, 256]),\n",
    "        activation=\"relu\",\n",
    "    )(x)\n",
    "\n",
    "    x = Dropout(\n",
    "        hp.Choice(\"dropout1\", values=[0.1, 0.2, 0.3])\n",
    "    )(x)\n",
    "\n",
    "    x = Dense(\n",
    "        units=hp.Choice(\"units_2\", values=[16, 32, 64]),\n",
    "        activation=\"relu\",\n",
    "    )(x)\n",
    "\n",
    "    x = Dropout(\n",
    "        hp.Choice(\"dropout2\", values=[0.1, 0.2, 0.3])\n",
    "    )(x)\n",
    "\n",
    "    # Final layer\n",
    "    output = Dense(units=5, activation='softmax')(x)\n",
    "\n",
    "    # ---- Model ----\n",
    "    model = Model(inputs=input_2d, outputs=output)\n",
    "    learning_rate = hp.Choice(\n",
    "        \"learning_rate\",\n",
    "        values=[2e-4, 5e-4, 1e-5, 2e-5, 5e-5]\n",
    "    )\n",
    "\n",
    "    # Batch size tuned externally during training\n",
    "    hp.Choice(\"batch_size\", values=[32, 64, 128])\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(\n",
    "        learning_rate=learning_rate,\n",
    "        decay=0\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1462f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define batch sizes for hyperparameter tuning\n",
    "batch_sizes = hp.Choice( 'batch_size' , values=[ 32 , 64, 128 ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425e232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a HyperParameters object and build the model to test\n",
    "## set up the tuner using RandomSearch\n",
    "hp = keras_tuner.HyperParameters()\n",
    "model_builder( keras_tuner.HyperParameters() )\n",
    "\n",
    "\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=model_builder,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=100,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"tuning_model_multiclass\",\n",
    "    project_name=\"classify_all_types\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68389a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c515614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Early stopping callback \n",
    "# TensorBoard callback for training reports\n",
    "# Run the hyperparameter search and storing the results in tuner_results\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=30)\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard('tuning_model_multiclass/tb_logs/')\n",
    "\n",
    "tuner_results = tuner.search( x= trainImagesX , y=trainAttrX,  epochs=300 , validation_data=(testImagesX ,testAttrX) ,\n",
    "                    callbacks= [stop_early,tensorboard ]   ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56e3e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the tuner results summary\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab4a324",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=10)\n",
    "best_model = models[0]\n",
    "                    \n",
    "# Save the best models]\n",
    "for i in range(0,10):\n",
    "    models[i].save('path/to/directory/best_model_' + str(i), save_format ='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ea87e8",
   "metadata": {},
   "source": [
    "For testing with the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf373cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing with the simulated dataset\n",
    "loss, acc = best_model.evaluate(testingImagesX, testingAttrX, verbose=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a48d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing with the chime data\n",
    "predictions = best_model.predict( chime_test ) \n",
    "\n",
    "predicted_classes = np.argmax(predictions , axis =1 )\n",
    "test_labels = np.argmax( chime_test_labels, axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cfd6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## classification report \n",
    "report= classification_report(test_labels, predicted_classes, target_names=['A' ,'B', 'C', 'C1', 'C2'] )\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
