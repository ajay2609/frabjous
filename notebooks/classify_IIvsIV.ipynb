{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FRB Type II vs Type IV Classification \n",
    "\n",
    "This notebook explores CNN-based classification of simulated\n",
    "type II and type IV morphology of the FRBs as described in the Kumar et. al. 2025\n",
    "\n",
    "### Notes\n",
    "- Training data is generated using simulation scripts in the folder frabjous_sim.\n",
    "- This notebook is used  to obtain the hyperparameter optimised models.\n",
    "- the type II here is refered to as type B \n",
    "- the type IV here is refered to as type C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "from sklearn.metrics import  ConfusionMatrixDisplay\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import locale\n",
    "import time\n",
    "import datetime\n",
    "import json \n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import keras.layers as KL\n",
    "import keras.models as KM\n",
    "import keras.optimizers as KO\n",
    "import keras.callbacks as KC\n",
    "import keras.utils as KU\n",
    "import keras.preprocessing.image as KI\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Concatenate,Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D \n",
    "from keras.models import Model\n",
    "import keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This is base directory where you will keep the generated FRB samples\n",
    "\n",
    "BASE_DIR = os.getenv(\"base_directory\", \".\") ## Set your base directory here by default it is current directory\n",
    "\n",
    "print(f\"Using BASE_DIR = {BASE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can either create your own training dataset using the simulation scripts provided in the repo or you can download the data from the following link for training \n",
    "\n",
    "Link: https://drive.google.com/file/d/1gABgy59nyHcNOffODCyzDRfNvvt4t29B/view?usp=drive_link\n",
    "\n",
    "After downloading, unzip the archive before running the analysis cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Data Directory Structure\n",
    "\n",
    "<pre>\n",
    "&lt;BASE_DIR&gt;/\n",
    "├── simfrb/\n",
    "│   ├── simdata/\n",
    "│   │   ├── type_B/\n",
    "│   │   │   ├── SNR_15/\n",
    "│   │   │   ├── SNR_25/\n",
    "│   │   │   ├── SNR_35/\n",
    "│   │   │   ├── SNR_50/\n",
    "│   │   │   └── SNR_100/\n",
    "│   │   └── type_C2/\n",
    "│   │       ├── SNR_15/\n",
    "│   │       ├── SNR_25/\n",
    "│   │       ├── SNR_35/\n",
    "│   │       ├── SNR_50/\n",
    "│   │       └── SNR_100/\n",
    "</pre>\n",
    "\n",
    "#### Notes\n",
    "- `type B` corresponds to **Type II FRBs**\n",
    "- `type C2` corresponds to **Type V FRBs**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type1 and type2 define the two morphology labels used throughout the notebook (e.g., type1 = 'B', type2 = 'C1').\n",
    "# These variables are used by the data-loading functions to construct file paths to locate the corresponding `.npz` and `.json` files.\n",
    "# type1 is treated as the negative class (label 0) and `type2` as the positive class (label 1) for the binary classification tasks.\n",
    "# Changing these values will change which classes are loaded for training, validation, and testing.\n",
    "\n",
    "type1 = 'B'\n",
    "type2 = 'C1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read indices from a text files \n",
    "def read_indices(fname):\n",
    "    indices = []\n",
    "    with open(SIMFRB_DIR / fname) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                indices.append(int(line))\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.experimental.enable_tf_random_generator()\n",
    "tf.keras.utils.set_random_seed(1334534)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMFRB_DIR = Path(BASE_DIR) / \"simfrb\"\n",
    "### We identified several examples in type C1 which look like single component\n",
    "### These examples are then filtered out from the training dataset --- remove_type_C1_SNR_XX.txt files contain the indices of such examples\n",
    "\n",
    "#### loading the indices for type C1 samples to exlude from training data \n",
    "remove_indices_C1_100 = read_indices(\"remove_type_C1_SNR_100.txt\")\n",
    "remove_indices_C1_50  = read_indices(\"remove_type_C1_SNR_50.txt\")\n",
    "remove_indices_C1_35  = read_indices(\"remove_type_C1_SNR_35.txt\")\n",
    "remove_indices_C1_25  = read_indices(\"remove_type_C1_SNR_25.txt\")\n",
    "indices_C1_15 = read_indices(\"type_C1_SNR_15.txt\")\n",
    "remove_indices_C1_15 = [x for x in np.arange(0, 1000) if x not in indices_C1_15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#function to read data \n",
    "\n",
    "def read_data(type1,type2,snr,remove_indices):\n",
    "    \"\"\"\n",
    "    Load simulated FRB images and labels for two morphology classes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    type1, type2 : str\n",
    "        FRB morphology labels (e.g., 'B', 'C1').\n",
    "    snr : str\n",
    "        Signal-to-noise ratio label (e.g., '50').\n",
    "    remove_indices : list of int\n",
    "        Indices of simulated FRBs to exclude (applied to type2 only).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    labels : list\n",
    "        Binary class labels.\n",
    "    images : list\n",
    "        Normalized 2D FRB dynamic spectra.\n",
    "    \"\"\"\n",
    "\n",
    "    base_path = os.path.join(BASE_DIR, \"simfrb\", \"simdata\", \"type_\")\n",
    "\n",
    "    # ---- Load metadata ----\n",
    "    with open(f\"{base_path}{type1}/SNR_{snr}/frb_header_type_{type1}.json\") as f:\n",
    "        class1_labels = json.load(f)\n",
    "\n",
    "    with open(f\"{base_path}{type2}/SNR_{snr}/frb_header_type_{type2}.json\") as f:\n",
    "        class2_labels = json.load(f)\n",
    "\n",
    "    # ---- Load image data ----\n",
    "    frbd1 = np.load(\n",
    "        f\"{base_path}{type1}/SNR_{snr}/simulatefrbs_type_{type1}.npz\"\n",
    "    )[\"arr_0\"]\n",
    "\n",
    "    frbd2 = np.load(\n",
    "        f\"{base_path}{type2}/SNR_{snr}/simulatefrbs_type_{type2}.npz\"\n",
    "    )[\"arr_0\"]\n",
    "           \n",
    "    frbdn = []\n",
    "    frbdl = []\n",
    "    frbdm = []\n",
    "    frbdi = []\n",
    "    for i in range(0,len(frbd2)):\n",
    "            if i in remove_indices : \n",
    "                continue\n",
    "            else :\n",
    "                immax = frbd1[i].max() \n",
    "                frbdn.append(frbd1[i]/(immax/255))\n",
    "                frbdl.append(0)\n",
    "                frbdm.append(immax)\n",
    "                frbdi.append(i)\n",
    "\n",
    "                immax = frbd2[i].max()\n",
    "                frbdn.append(frbd2[i]/(immax/255))\n",
    "                frbdl.append(1)\n",
    "                frbdm.append(immax)\n",
    "                frbdi.append(i)\n",
    "\n",
    "    return frbdl,frbdn \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for different SNR levels, applying the respective removal indices    \n",
    "frbdl, frbdn = read_data(type1, type2, '100', remove_indices_C1_100)\n",
    "\n",
    "temp_labels, temp_data = read_data(type1, type2, '50', remove_indices_C1_50)\n",
    "frbdl = frbdl + temp_labels\n",
    "frbdn = frbdn + temp_data\n",
    "\n",
    "temp_labels, temp_data = read_data(type1, type2, '35', remove_indices_C1_35)\n",
    "frbdl = frbdl + temp_labels\n",
    "frbdn = frbdn + temp_data\n",
    "\n",
    "temp_labels, temp_data = read_data(type1, type2, '25', remove_indices_C1_25)\n",
    "frbdl = frbdl + temp_labels\n",
    "frbdn = frbdn + temp_data\n",
    "\n",
    "temp_labels, temp_data = read_data(type1, type2, '15', remove_indices_C1_15)\n",
    "frbdl = frbdl + temp_labels\n",
    "frbdn = frbdn + temp_data\n",
    "\n",
    "frbdn = np.asarray(frbdn)\n",
    "frbdn.shape += 1,\n",
    "frbdl = np.asarray(frbdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "input_shape = (frbdn.shape[1] , frbdn.shape[2],1) #define input shape for model\n",
    "split = train_test_split(frbdl, frbdn, test_size=0.15, random_state=42)\n",
    "(trainAttrX, testingAttrX, trainImagesX, testingImagesX) = split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further split training data into training and validation sets\n",
    "split = train_test_split(trainAttrX, trainImagesX, test_size=0.2, random_state=42)\n",
    "(trainAttrX, testAttrX, trainImagesX, testImagesX) = split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fuction to build model which is used for training and hyperparameter tuning\n",
    "\n",
    "def model_builder(hp):\n",
    "    \"\"\"\n",
    "    CNN based model builder for hyperparameter tuning\n",
    "    \"\"\"\n",
    "\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    ######    CNN layers  #########\n",
    "    model.add(Conv2D(32, (3, 3), activation=\"relu\",\n",
    "                     input_shape=(256, 256, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (5, 5), activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    ###### fully connected layers #######\n",
    "    model.add(\n",
    "        Dense(\n",
    "            units=hp.Choice(\"units_1\", values=[16, 32, 64]),\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        Dropout(\n",
    "            hp.Choice(\"dropout1\", values=[0.15, 0.2, 0.25, 0.3])\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        Dense(\n",
    "            units=hp.Choice(\"units_2\", values=[4, 8, 16, 32]),\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        Dropout(\n",
    "            hp.Choice(\"dropout2\", values=[0.15, 0.2, 0.25, 0.3])\n",
    "        )\n",
    "    )\n",
    "\n",
    "    \n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    ###### Optimizer hyperparameters #####\n",
    "    hp_learning_rate = hp.Choice(\n",
    "        \"learning_rate\",\n",
    "        values=[2e-4, 5e-4, 1e-5, 2e-5, 5e-5],\n",
    "    )\n",
    "\n",
    "    # Batch size is tuned at the training stage, not inside the model\n",
    "    hp.Choice(\"batch_size\", values=[32, 64, 128])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            learning_rate=hp_learning_rate\n",
    "        ),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Create a HyperParameters object and build the model to test\n",
    "\n",
    "hp = keras_tuner.HyperParameters()\n",
    "model_builder(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define batch sizes for hyperparameter tuning\n",
    "batch_sizes = hp.Choice( 'batch_size' , values=[ 32 , 64, 128 ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## set up the tuner using RandomSearch\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=model_builder,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=100,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True,\n",
    "    directory=os.path.join(BASE_DIR, \"model_tuning_b_c1\")\n",
    "    project_name=\"classify_b_c1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## display the search space summary\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Early stopping callback \n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard callback for training reports\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=os.path.join(BASE_DIR, \"model_tuning_b_c1/\", \"tensorboard_logs\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the hyperparameter search\n",
    "tuner.search( x= trainImagesX, y=trainAttrX, epochs = 200, validation_data=(testImagesX, testAttrX)  , callbacks= [stop_early,tensorboard ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the best models from the hyperparameter search\n",
    "models = tuner.get_best_models(num_models=10)\n",
    "best_model = models[0]\n",
    "\n",
    "# Explicitly build the model to enable summary display\n",
    "best_model.build(input_shape=(None, 256, 256, 1))\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display the tuner results summary\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = tuner.get_best_models(num_models=10)\n",
    "\n",
    "best_model = models[0]\n",
    "\n",
    "# Save the best models\n",
    "for i in range(0,10):\n",
    "    models[i].save('/path/to/directory/best_model_' + str(i), save_format ='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(5)\n",
    "# Build the model with the best hyperparameters.\n",
    "model = model_builder(best_hps[0])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing with the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model on the test dataset\n",
    "predictions = best_model.predict(testingImagesX)\n",
    "predictions_bool = (predictions > 0.5)\n",
    "cm_1 = confusion_matrix( testingAttrX , predictions_bool, labels=[0 , 1])\n",
    "cm_1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get loss and accuracy for the best model on the test dataset\n",
    "loss, acc = best_model.evaluate(testingImagesX, testingAttrX, verbose=2 )\n",
    "f1score = f1_score(testingAttrX, predictions_bool)\n",
    "print(round(acc ,4), round(f1score,4 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the FPR-FNR curve for the best model\n",
    "fpr, tpr, thresholds = roc_curve(testingAttrX, predictions)\n",
    "\n",
    "plt.rc('font', size=10)\n",
    "plt.plot(np.flip(thresholds[1:]), np.flip(fpr[1:])*100,label='False Positive Rate')\n",
    "plt.plot(np.flip(thresholds[1:]), np.flip(1-tpr[1:])*100,label='False Negative Rate')\n",
    "plt.xlabel('Threshold',fontsize = 20)\n",
    "plt.ylabel('Cumulative percentage',fontsize = 10)\n",
    "plt.title('FPR FNR vs threshold ',fontsize = 10)\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "#plt.setp(ax4.get_xticklabels(), fontsize=15)\n",
    "#plt.setp(ax4.get_yticklabels(), fontsize=15)    \n",
    "plt.grid(True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
