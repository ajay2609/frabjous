{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82fe2e6e",
   "metadata": {},
   "source": [
    "# FRB classification of all types of morphology \n",
    "\n",
    "This notebook explores CNN-based classification of mutiple classes\n",
    "type I, type II, type III, type IV and type IV morphology of the FRBs as described in the Kumar et. al. 2025\n",
    "\n",
    "## Notes\n",
    "- Training data is generated using simulation scripts in the folder frabjous_sim.\n",
    "- This notebook is used  to obtain the hyperparameter optimised models.\n",
    "- the type I here is refered to as type A \n",
    "- the tyoe II here is refered to as type B\n",
    "- the tyoe II here is refered to as type C\n",
    "- the tyoe IV here is refered to as type C1\n",
    "- the type V here is refered to as type C2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8f3f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "from sklearn.metrics import  ConfusionMatrixDisplay\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import locale\n",
    "import time\n",
    "import datetime\n",
    "import json \n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import keras.layers as KL\n",
    "import keras.models as KM\n",
    "import keras.optimizers as KO\n",
    "import keras.callbacks as KC\n",
    "import keras.utils as KU\n",
    "import keras.preprocessing.image as KI\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Concatenate,Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D \n",
    "from keras.models import Model\n",
    "import keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11569d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.experimental.enable_tf_random_generator()\n",
    "tf.keras.utils.set_random_seed(1354534)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f881de",
   "metadata": {},
   "outputs": [],
   "source": [
    "type1 = 'A'\n",
    "type2 = 'B'\n",
    "type3 = 'C'\n",
    "type4 = 'C1'\n",
    "type5 = 'C2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e7bd4a",
   "metadata": {},
   "source": [
    "## Expected Data Directory Structure\n",
    "\n",
    "\n",
    "<pre>\n",
    "&lt;BASE_DIR&gt;/\n",
    "├── simfrb/\n",
    "│   ├── simdata/\n",
    "│   │   ├── type_A/\n",
    "│   │   │   ├── SNR_15/\n",
    "│   │   │   ├── SNR_25/\n",
    "│   │   │   ├── SNR_35/\n",
    "│   │   │   ├── SNR_50/\n",
    "│   │   │   └── SNR_100/\n",
    "│   │   └── type_B/\n",
    "│   │       ├── SNR_15/\n",
    "│   │       ├── SNR_25/\n",
    "│   │       ├── SNR_35/\n",
    "│   │       ├── SNR_50/\n",
    "│   │       └── SNR_100/\n",
    "|   |   .\n",
    "|   |   .\n",
    "|   |   .\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d902a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_indices(fname):\n",
    "    indices = []\n",
    "    with open(SIMFRB_DIR / fname) as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                indices.append(int(line))\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f367584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(type1, type2, snr, remove_indices_C1, remove_indices_C2):\n",
    "    \"\"\"\n",
    "    Load Simulated FRB 2-D dynamic spectra and labels for two archetypes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    type1, type2 : str\n",
    "        FRB morphology labels (e.g., 'B', 'C1').\n",
    "    snr : str\n",
    "        Signal-to-noise ratio label (e.g., '50').\n",
    "    remove_indices_C1 : list of int\n",
    "        Indices of simulated FRBs to exclude for type1.\n",
    "    remove_indices_C2 : list of int\n",
    "        Indices of simulated FRBs to exclude for type2.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    labels : list\n",
    "        Binary class labels.\n",
    "    images : list\n",
    "        Normalized 2D FRB dynamic spectra.\n",
    "    \"\"\"\n",
    "\n",
    "    base_path = os.path.join(BASE_DIR, \"simfrb\", \"simdata\", \"type_\")\n",
    "\n",
    "    # ---- Load metadata ----\n",
    "    with open(f\"{base_path}{type1}/SNR_{snr}/frb_header_type_{type1}.json\") as f:\n",
    "        class1_labels = json.load(f)\n",
    "\n",
    "    with open(f\"{base_path}{type2}/SNR_{snr}/frb_header_type_{type2}.json\") as f:\n",
    "        class2_labels = json.load(f)\n",
    "\n",
    "    # ---- Load image data ----\n",
    "    frbd1 = np.load(\n",
    "        f\"{base_path}{type1}/SNR_{snr}/simulatefrbs_type_{type1}.npz\"\n",
    "    )[\"arr_0\"]\n",
    "\n",
    "    frbd2 = np.load(\n",
    "        f\"{base_path}{type2}/SNR_{snr}/simulatefrbs_type_{type2}.npz\"\n",
    "    )[\"arr_0\"]\n",
    "\n",
    "    frbd3 = np.load(\n",
    "        f\"{base_path}{type3}/SNR_{snr}/simulatefrbs_type_{type3}.npz\"\n",
    "    )[\"arr_0\"]\n",
    "\n",
    "    frbd4 = np.load(\n",
    "        f\"{base_path}{type4}/SNR_{snr}/simulatefrbs_type_{type4}.npz\"\n",
    "    )[\"arr_0\"]\n",
    "\n",
    "    frbd5 = np.load(\n",
    "        f\"{base_path}{type5}/SNR_{snr}/simulatefrbs_type_{type5}.npz\"\n",
    "    )[\"arr_0\"]\n",
    "\n",
    "    frbdn = []\n",
    "    frbdl = []\n",
    "\n",
    "    for i in range(len(frbd1)):\n",
    "        if i in remove_indices_C1:\n",
    "            continue\n",
    "        else:\n",
    "            immax = frbd1[i].max() \n",
    "            frbdn.append(frbd1[i]/(immax/255))\n",
    "            frbdl.append([1.,0.,0.,0.,0.])\n",
    "\n",
    "            immax = frbd2[i].max()\n",
    "            frbdn.append(frbd2[i]/(immax/255))\n",
    "            frbdl.append([0.,1.,0.,0.,0.])\n",
    "\n",
    "            immax = frbd3[i].max()\n",
    "            frbdn.append(frbd2[i]/(immax/255))\n",
    "            frbdl.append([0.,0.,1.,0.,0.])\n",
    "                            \n",
    "            immax = frbd4[i].max()\n",
    "            frbdn.append(frbd4[i]/(immax/255))\n",
    "            frbdl.append([0.,0.,0.,1.,0.])\n",
    "\n",
    "    for i in range(len(frbd2)):\n",
    "        if i in remove_indices_C2:\n",
    "            continue\n",
    "        else:\n",
    "            immax = frbd5[i].max()\n",
    "            frbdn.append(frbd5[i]/(immax/255))\n",
    "            frbdl.append([0.,0.,0.,0.,1.])\n",
    "\n",
    "    return frbdl, frbdn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32830d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_chime_data(data_file, label_file):\n",
    "    \"\"\"\n",
    "    Load CHIME FRB images and correct labels.\n",
    "\n",
    "    This function reads interpolated CHIME FRB dynamic spectra and their\n",
    "    corresponding labels, normalizes each image, and splits\n",
    "    the data into training and test subsets by class.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_file : str\n",
    "        Path to the NumPy `.npz` file containing FRB images.\n",
    "    label_file : str\n",
    "        Path to a text file containing morphology labels\n",
    "        (one per line: A, B, C, C1, or C2).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    labels_train : list\n",
    "        One-hot encoded labels for training data.\n",
    "    images_train : list\n",
    "        Normalized FRB images for training.\n",
    "    images_test : list\n",
    "        Normalized FRB images for testing.\n",
    "    labels_test : list\n",
    "        One-hot encoded labels for testing data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Containers for each morphology class\n",
    "    frbdn1, frbdn2, frbdn3, frbdn4, frbdn5 = [], [], [], [], []\n",
    "    frbdl1, frbdl2, frbdl3, frbdl4, frbdl5 = [], [], [], [], []\n",
    "\n",
    "    # ---- Load data ----\n",
    "    with np.load(data_file) as frbdata:\n",
    "        frbd = frbdata[\"arr_0\"]\n",
    "\n",
    "    with open(label_file) as f:\n",
    "        correct_type = f.readlines()\n",
    "\n",
    "    # ---- Assign images and labels ----\n",
    "    for i in range(len(correct_type)):\n",
    "        immax = frbd[i].max()\n",
    "        norm_img = frbd[i] / (immax / 255)\n",
    "\n",
    "        if correct_type[i] == \"A\\n\":\n",
    "            frbdn1.append(norm_img)\n",
    "            frbdl1.append([1., 0., 0., 0., 0.])\n",
    "\n",
    "        if correct_type[i] == \"B\\n\":\n",
    "            frbdn2.append(norm_img)\n",
    "            frbdl2.append([0., 1., 0., 0., 0.])\n",
    "\n",
    "        if correct_type[i] == \"C\\n\":\n",
    "            frbdn3.append(norm_img)\n",
    "            frbdl3.append([0., 0., 1., 0., 0.])\n",
    "\n",
    "        if correct_type[i] == \"C1\\n\":\n",
    "            frbdn4.append(norm_img)\n",
    "            frbdl4.append([0., 0., 0., 1., 0.])\n",
    "\n",
    "        if correct_type[i] == \"C2\\n\":\n",
    "            frbdn5.append(norm_img)\n",
    "            frbdl5.append([0., 0., 0., 0., 1.])\n",
    "\n",
    "    # ---- Train / test split (per class) ----\n",
    "    lenA  = int(len(frbdn1) / 2)\n",
    "    lenB  = int(len(frbdn2) / 2)\n",
    "    lenC  = int(len(frbdn3) / 2)\n",
    "    lenC1 = int(len(frbdn4) / 2)\n",
    "    lenC2 = int(len(frbdn5) / 2)\n",
    "\n",
    "    images_train = (\n",
    "        frbdn1[:lenA] +\n",
    "        frbdn2[:lenB] +\n",
    "        frbdn3[:lenC] +\n",
    "        frbdn4[:lenC1] +\n",
    "        frbdn5[:lenC2]\n",
    "    )\n",
    "\n",
    "    labels_train = (\n",
    "        frbdl1[:lenA] +\n",
    "        frbdl2[:lenB] +\n",
    "        frbdl3[:lenC] +\n",
    "        frbdl4[:lenC1] +\n",
    "        frbdl5[:lenC2]\n",
    "    )\n",
    "\n",
    "    images_test = (\n",
    "        frbdn1[lenA:] +\n",
    "        frbdn2[lenB:] +\n",
    "        frbdn3[lenC:] +\n",
    "        frbdn4[lenC1:] +\n",
    "        frbdn5[lenC2:]\n",
    "    )\n",
    "\n",
    "    labels_test = (\n",
    "        frbdl1[lenA:] +\n",
    "        frbdl2[lenB:] +\n",
    "        frbdl3[lenC:] +\n",
    "        frbdl4[lenC1:] +\n",
    "        frbdl5[lenC2:]\n",
    "    )\n",
    "\n",
    "    return labels_train, images_train,  labels_test, images_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e017e83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMFRB_DIR = Path(BASE_DIR) / \"simfrb\"\n",
    "\n",
    "#### loading the indices for type C1 samples to exlude from training data #######\n",
    "remove_indices_C1_100 = read_indices(\"remove_type_C1_SNR_100.txt\")\n",
    "remove_indices_C1_50  = read_indices(\"remove_type_C1_SNR_50.txt\")\n",
    "remove_indices_C1_35  = read_indices(\"remove_type_C1_SNR_35.txt\")\n",
    "remove_indices_C1_25  = read_indices(\"remove_type_C1_SNR_25.txt\")\n",
    "\n",
    "indices_C1_15 = read_indices(\"type_C1_SNR_15.txt\")\n",
    "remove_indices_C1_15 = [x for x in np.arange(0, 1000) if x not in indices_C1_15]\n",
    "\n",
    "\n",
    "#### loading the indices for type C2 samples to exlude from training data #######\n",
    "remove_indices_C2_100 = read_indices(\"type_C2_SNR_100.txt\")\n",
    "remove_indices_C2_50  = read_indices(\"type_C2_SNR_50.txt\")\n",
    "remove_indices_C2_35  = read_indices(\"type_C2_SNR_35.txt\")\n",
    "remove_indices_C2_25  = read_indices(\"type_C2_SNR_25.txt\")\n",
    "\n",
    "indices_C2_15 = read_indices(\"type_C2_SNR_15.txt\")\n",
    "remove_indices_C2_15 = [x for x in np.arange(0, 1000) if x not in indices_C2_15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436d4e8b",
   "metadata": {},
   "source": [
    "Loading the training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507f1c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SNR_100\n",
    "frbdl, frbdn = read_data('100', remove_indices_C1_100, remove_indices_C2_100)\n",
    "\n",
    "# SNR_50\n",
    "temp_labels, temp_data = read_data('50', remove_indices_C1_50, remove_indices_C2_50)\n",
    "frbdl = frbdl + temp_labels[:]\n",
    "frbdn = frbdn + temp_data[:]\n",
    "\n",
    "# SNR_35\n",
    "temp_labels, temp_data = read_data('35', remove_indices_C1_35, remove_indices_C2_35)\n",
    "frbdl = frbdl + temp_labels[:]\n",
    "frbdn = frbdn + temp_data[:]\n",
    "\n",
    "# SNR_25\n",
    "temp_labels, temp_data = read_data('25', remove_indices_C1_25, remove_indices_C2_25)\n",
    "frbdl = frbdl + temp_labels[:]\n",
    "frbdn = frbdn + temp_data[:]\n",
    "\n",
    "# SNR_15\n",
    "temp_labels, temp_data = read_data('15', remove_indices_C1_15, remove_indices_C2_15)\n",
    "frbdl = frbdl + temp_labels[:]\n",
    "frbdn = frbdn + temp_data[:]\n",
    "\n",
    "# reading the chime data\n",
    "## chime bursts with interpolation and their label file are provided in the directory\n",
    "chime_labels, chime_data, chime_test_labels, chime_test_data = read_chime_data('files/chime_interp_frbs.npz','files/check.txt.txt')\n",
    "frbdl = frbdl + chime_labels[:]\n",
    "frbdn = frbdn + chime_data[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7914587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "frbdn = np.asarray(frbdn)     \n",
    "frbdn.shape += 1,\n",
    "frbdl = np.asarray(frbdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae4b22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = train_test_split(frbdl, frbdn, test_size=0.20, random_state=42)\n",
    "(trainAttrX, testingAttrX, trainImagesX, testingImagesX) = split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2d75a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = train_test_split(trainAttrX, trainImagesX, test_size=0.2, random_state=42)\n",
    "(trainAttrX, testAttrX, trainImagesX, testImagesX) = split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec5eedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    \"\"\"\n",
    "    Build a 2D CNN classifier for FRB morphology classification.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    hp : keras_tuner.HyperParameters\n",
    "        Hyperparameter object used by Keras Tuner.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : keras.Model\n",
    "        Compiled Keras model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Input\n",
    "    input_2d = Input(shape=(256, 256, 1))\n",
    "\n",
    "    # CNN layers \n",
    "    x = Conv2D(filters=32, kernel_size=3, activation='relu')(input_2d)\n",
    "    x = MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "    x = Conv2D(filters=32, kernel_size=3, activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "    x = Conv2D(filters=32, kernel_size=3, activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=5)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # Fully connected layers \n",
    "    x = Dense(\n",
    "        units=hp.Choice(\"units_1\", values=[64, 128, 256]),\n",
    "        activation=\"relu\",\n",
    "    )(x)\n",
    "\n",
    "    x = Dropout(\n",
    "        hp.Choice(\"dropout1\", values=[0.1, 0.2, 0.3])\n",
    "    )(x)\n",
    "\n",
    "    x = Dense(\n",
    "        units=hp.Choice(\"units_2\", values=[16, 32, 64]),\n",
    "        activation=\"relu\",\n",
    "    )(x)\n",
    "\n",
    "    x = Dropout(\n",
    "        hp.Choice(\"dropout2\", values=[0.1, 0.2, 0.3])\n",
    "    )(x)\n",
    "\n",
    "    # Final layer\n",
    "    output = Dense(units=5, activation='softmax')(x)\n",
    "\n",
    "    # ---- Model ----\n",
    "    model = Model(inputs=input_2d, outputs=output)\n",
    "    learning_rate = hp.Choice(\n",
    "        \"learning_rate\",\n",
    "        values=[2e-4, 5e-4, 1e-5, 2e-5, 5e-5]\n",
    "    )\n",
    "\n",
    "    # Batch size tuned externally during training\n",
    "    hp.Choice(\"batch_size\", values=[32, 64, 128])\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(\n",
    "        learning_rate=learning_rate,\n",
    "        decay=0\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425e232a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = keras_tuner.HyperParameters()\n",
    "model_builder( keras_tuner.HyperParameters() )\n",
    "\n",
    "\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=model_builder,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=100,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"tuning_model_multiclass\",\n",
    "    project_name=\"classify_all_types\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c515614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=30)\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard('tuning_model_multiclass/tb_logs/')\n",
    "\n",
    "tuner_results = tuner.search( x= trainImagesX , y=trainAttrX,  epochs=300 , validation_data=(testImagesX ,testAttrX) ,\n",
    "                    callbacks= [stop_early,tensorboard ]   ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56e3e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab4a324",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=10)\n",
    "for i in range(0,10):\n",
    "    models[i].save('path/to/directory/best_model_' + str(i), save_format ='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ea87e8",
   "metadata": {},
   "source": [
    "For testing with the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f642da",
   "metadata": {},
   "outputs": [],
   "source": [
    "### this model is provided in the models folder ###\n",
    "best_model = tf.keras.models.load_model('models/model_single_multi/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf373cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing with the simulated dataset\n",
    "loss, acc = best_model.evaluate(testingImagesX, testingAttrX, verbose=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a48d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "## testing with the chime data\n",
    "predictions = best_model.predict( chime_test ) \n",
    "\n",
    "predicted_classes = np.argmax(predictions , axis =1 )\n",
    "test_labels = np.argmax( chime_test_labels, axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cfd6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## classification report \n",
    "report= classification_report(test_labels, predicted_classes, target_names=['A' ,'B', 'C', 'C1', 'C2'] )\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
